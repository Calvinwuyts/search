# Purpose
This package is a small library for extracting information in (relatively) human-readable form from our
ELK-stack logging framework. Note that this logging framework issues bespoke messages in a unique format; these classes are not easily generalisable to parsing logs from other sources.

# Overview

The overall procedure for extracting information from the logs is:

1. First, we loop through the logs between two designated temporal endpoints, extracting session IDs
2. Then we retrieve all search-related queries and actions associated with these session IDs
3. Optionally, these search-related queries and actions may be further processed or mined for analytics data and/or readability.

Step 1 is performed by the `SessionExtractor` object. For example, to retrieve all sessions for the month of October 2017, one would enter:

```
cd ..
python3
>>> from log_extractor import session_extractor
>>> se = session_extractor.SessionExtractor("2017-10-01", "2017-11-01")
```

This will retrieve all cookie-based user IDs encountered by the Search API during that time, writing the results to the `intermediate_output/sessions` directory.

Step 2 is performed by the `EntryExtractor`. The `EntryExtractor` reads the lists of user IDs generated by the `SessionExtractor`, queries the ELK-stack for all interactions undertaken using that ID, and outputs a series of files recording these in (relatively) human-readable format to the `intermediate_output/entries_by_session` directory.

```
>>> from log_extractor import entry_extractor
>>> ee = entry_extractor.EntryExtractor("2017-10-01", "2017-11-01")
>>> ee.extract_entries()
```

After this a number of possibilities arise. For example, the `FieldAndTermExractor` extracts a list of named fields used in search, and the associated search terms; the `TermExtractor` extracts just the terms; etc. 

Note that this code is packed in an object-oriented and modular fashion. In other words, they are to be run as imported objects, rather than as scripts.
